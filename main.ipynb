{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f85403a-16e9-42b1-a3fd-5ec75030d6dd",
   "metadata": {},
   "source": [
    "# Goal\n",
    "\n",
    "- Show daily average data on the paralel exchange rate of the Argentinian Peso and the US dollar\n",
    "- Render basic financial indicators for this paralel exchange rate\n",
    "- Using argentinian front page newspapers, predict the rise or fall of the paralel currency exchange\n",
    "\n",
    "### Warning\n",
    "\n",
    "The paralel exchange rate of ARSUSD is not the same that will appear in a google search for ARSUSD. This is the value used by daily transactions between third parties in Argentina. It is also called \"dollar blue\" or \"informal dollar\". From now on, I am going to call it \"informal dollar\" from now on\n",
    "\n",
    "## Why am I doing this?\n",
    "\n",
    "I think this is an interesting proyect for a few reasons\n",
    "\n",
    "- This currency exchange rate is not available for most trading tools, because it is not the dollar exchange rate that companies or the government use. However, it is widely used to decide most prices of other products inside Argentina, and it shapes the daily lives of the argentinian people. It has been called \"the stability thermometer of the country\". \n",
    "\n",
    "- Also, from a purely ML/DS perspective, will it be even possible to predict the behaviour of this currency exchange rate based on newspaper front pages? Although I am not sure, I am willing to try and see."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd5146c-368b-44bf-b87c-7858d5440500",
   "metadata": {
    "tags": []
   },
   "source": [
    "First, lets capture the informal dollar prices from a known source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a8acb51b-7357-4739-960a-36e24fba5161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/synics-dev/.local/lib/python3.9/site-packages (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.9/dist-packages (from pandas) (1.22.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/synics-dev/.local/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/synics-dev/.local/lib/python3.9/site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: plotly in /home/synics-dev/.local/lib/python3.9/site-packages (5.6.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /home/synics-dev/.local/lib/python3.9/site-packages (from plotly) (8.0.1)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from plotly) (1.16.0)\n",
      "Requirement already satisfied: jupyter_dash in /home/synics-dev/.local/lib/python3.9/site-packages (0.4.1)\n",
      "Requirement already satisfied: ipykernel in /home/synics-dev/.local/lib/python3.9/site-packages (from jupyter_dash) (6.9.1)\n",
      "Requirement already satisfied: flask in /home/synics-dev/.local/lib/python3.9/site-packages (from jupyter_dash) (2.0.3)\n",
      "Requirement already satisfied: dash in /home/synics-dev/.local/lib/python3.9/site-packages (from jupyter_dash) (2.2.0)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from jupyter_dash) (2.25.1)\n",
      "Requirement already satisfied: retrying in /home/synics-dev/.local/lib/python3.9/site-packages (from jupyter_dash) (1.3.3)\n",
      "Requirement already satisfied: ansi2html in /home/synics-dev/.local/lib/python3.9/site-packages (from jupyter_dash) (1.7.0)\n",
      "Requirement already satisfied: ipython in /home/synics-dev/.local/lib/python3.9/site-packages (from jupyter_dash) (8.1.0)\n",
      "Requirement already satisfied: dash-core-components==2.0.0 in /home/synics-dev/.local/lib/python3.9/site-packages (from dash->jupyter_dash) (2.0.0)\n",
      "Requirement already satisfied: dash-html-components==2.0.0 in /home/synics-dev/.local/lib/python3.9/site-packages (from dash->jupyter_dash) (2.0.0)\n",
      "Requirement already satisfied: plotly>=5.0.0 in /home/synics-dev/.local/lib/python3.9/site-packages (from dash->jupyter_dash) (5.6.0)\n",
      "Requirement already satisfied: dash-table==5.0.0 in /home/synics-dev/.local/lib/python3.9/site-packages (from dash->jupyter_dash) (5.0.0)\n",
      "Requirement already satisfied: flask-compress in /home/synics-dev/.local/lib/python3.9/site-packages (from dash->jupyter_dash) (1.11)\n",
      "Requirement already satisfied: Werkzeug>=2.0 in /home/synics-dev/.local/lib/python3.9/site-packages (from flask->jupyter_dash) (2.0.3)\n",
      "Requirement already satisfied: Jinja2>=3.0 in /home/synics-dev/.local/lib/python3.9/site-packages (from flask->jupyter_dash) (3.0.3)\n",
      "Requirement already satisfied: click>=7.1.2 in /home/synics-dev/.local/lib/python3.9/site-packages (from flask->jupyter_dash) (8.0.4)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in /home/synics-dev/.local/lib/python3.9/site-packages (from flask->jupyter_dash) (2.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/synics-dev/.local/lib/python3.9/site-packages (from Jinja2>=3.0->flask->jupyter_dash) (2.1.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /home/synics-dev/.local/lib/python3.9/site-packages (from plotly>=5.0.0->dash->jupyter_dash) (8.0.1)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from plotly>=5.0.0->dash->jupyter_dash) (1.16.0)\n",
      "Requirement already satisfied: brotli in /home/synics-dev/.local/lib/python3.9/site-packages (from flask-compress->dash->jupyter_dash) (1.0.9)\n",
      "Requirement already satisfied: tornado<7.0,>=4.2 in /usr/lib/python3/dist-packages (from ipykernel->jupyter_dash) (6.1)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in /home/synics-dev/.local/lib/python3.9/site-packages (from ipykernel->jupyter_dash) (1.5.1)\n",
      "Requirement already satisfied: jupyter-client<8.0 in /home/synics-dev/.local/lib/python3.9/site-packages (from ipykernel->jupyter_dash) (7.1.2)\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in /home/synics-dev/.local/lib/python3.9/site-packages (from ipykernel->jupyter_dash) (0.1.3)\n",
      "Requirement already satisfied: nest-asyncio in /home/synics-dev/.local/lib/python3.9/site-packages (from ipykernel->jupyter_dash) (1.5.4)\n",
      "Requirement already satisfied: traitlets<6.0,>=5.1.0 in /home/synics-dev/.local/lib/python3.9/site-packages (from ipykernel->jupyter_dash) (5.1.1)\n",
      "Requirement already satisfied: backcall in /home/synics-dev/.local/lib/python3.9/site-packages (from ipython->jupyter_dash) (0.2.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/synics-dev/.local/lib/python3.9/site-packages (from ipython->jupyter_dash) (0.18.1)\n",
      "Requirement already satisfied: decorator in /home/synics-dev/.local/lib/python3.9/site-packages (from ipython->jupyter_dash) (5.1.1)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/synics-dev/.local/lib/python3.9/site-packages (from ipython->jupyter_dash) (4.8.0)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/synics-dev/.local/lib/python3.9/site-packages (from ipython->jupyter_dash) (2.11.2)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /home/synics-dev/.local/lib/python3.9/site-packages (from ipython->jupyter_dash) (3.0.28)\n",
      "Requirement already satisfied: stack-data in /home/synics-dev/.local/lib/python3.9/site-packages (from ipython->jupyter_dash) (0.2.0)\n",
      "Requirement already satisfied: pickleshare in /home/synics-dev/.local/lib/python3.9/site-packages (from ipython->jupyter_dash) (0.7.5)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/lib/python3/dist-packages (from ipython->jupyter_dash) (52.0.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/synics-dev/.local/lib/python3.9/site-packages (from jedi>=0.16->ipython->jupyter_dash) (0.8.3)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in /home/synics-dev/.local/lib/python3.9/site-packages (from jupyter-client<8.0->ipykernel->jupyter_dash) (4.9.2)\n",
      "Requirement already satisfied: entrypoints in /home/synics-dev/.local/lib/python3.9/site-packages (from jupyter-client<8.0->ipykernel->jupyter_dash) (0.4)\n",
      "Requirement already satisfied: pyzmq>=13 in /home/synics-dev/.local/lib/python3.9/site-packages (from jupyter-client<8.0->ipykernel->jupyter_dash) (22.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/synics-dev/.local/lib/python3.9/site-packages (from jupyter-client<8.0->ipykernel->jupyter_dash) (2.8.2)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/synics-dev/.local/lib/python3.9/site-packages (from pexpect>4.3->ipython->jupyter_dash) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/synics-dev/.local/lib/python3.9/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->jupyter_dash) (0.2.5)\n",
      "Requirement already satisfied: executing in /home/synics-dev/.local/lib/python3.9/site-packages (from stack-data->ipython->jupyter_dash) (0.8.2)\n",
      "Requirement already satisfied: asttokens in /home/synics-dev/.local/lib/python3.9/site-packages (from stack-data->ipython->jupyter_dash) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in /home/synics-dev/.local/lib/python3.9/site-packages (from stack-data->ipython->jupyter_dash) (0.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pandas\n",
    "!pip3 install plotly\n",
    "!pip3 install jupyter_dash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "239336af-0833-4a1c-80fa-6ed4c5e4ab26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dash import Dash, html, dcc\n",
    "import plotly.express as px\n",
    "from jupyter_dash import JupyterDash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eac5dfae-16ae-4736-9c88-8a3751185cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "322c0705-00d0-49ad-be4e-91151eb3b4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add to the cell before\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d937a6ab-483d-48b9-8abd-f984051cfb5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-03-06 16:34:00--  https://mercados.ambito.com//dolar/informal/historico-general/01-01-2000/27-02-2022\n",
      "Resolving mercados.ambito.com (mercados.ambito.com)... 151.139.128.11\n",
      "Connecting to mercados.ambito.com (mercados.ambito.com)|151.139.128.11|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 150482 (147K) [application/json]\n",
      "Saving to: ‘raw_dolar_data’\n",
      "\n",
      "raw_dolar_data      100%[===================>] 146.96K   285KB/s    in 0.5s    \n",
      "\n",
      "2022-03-06 16:34:01 (285 KB/s) - ‘raw_dolar_data’ saved [150482/150482]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget 'https://mercados.ambito.com//dolar/informal/historico-general/01-01-2000/27-02-2022' -O raw_dolar_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cd3c6aa7-d97f-43bf-821b-ddad91177911",
   "metadata": {},
   "outputs": [],
   "source": [
    "dolar_price_raw_file = open('raw_dolar_data', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9f738aba-4231-4ba1-b890-471f40fed39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = dolar_price_raw_file.read()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "217976b4-3c47-4d1d-8db4-85102f0cbe9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dolar_prices = ast.literal_eval(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a7248a91-ca70-4474-a270-934df8e56ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fecha', 'Compra', 'Venta']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dolar_prices.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a0392aeb-ef1d-4979-b7bb-242ed03f9863",
   "metadata": {},
   "outputs": [],
   "source": [
    "dollar_df = pd.DataFrame(dolar_prices, columns=['date','buy_price', 'sell_price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d6d718-9728-4f99-8475-438c76f7f883",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "67d0d85d-3e43-442b-bca1-b8827b3d1bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dollar_df['date'] = pd.to_datetime(dollar_df['date'], format=\"%d-%m-%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "04b7e8ea-f52d-4584-a02f-564052ae1003",
   "metadata": {},
   "outputs": [],
   "source": [
    "dollar_df['buy_price']= [float(str(i).replace(',','.')) for i in dollar_df['buy_price']]\n",
    "dollar_df['sell_price']= [float(str(i).replace(',','.')) for i in dollar_df['sell_price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "36ca8004-0829-490e-9e80-29f97358a4d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>buy_price</th>\n",
       "      <th>sell_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-02-25</td>\n",
       "      <td>207.00</td>\n",
       "      <td>211.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-02-24</td>\n",
       "      <td>206.50</td>\n",
       "      <td>210.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-02-23</td>\n",
       "      <td>206.00</td>\n",
       "      <td>210.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-02-22</td>\n",
       "      <td>206.00</td>\n",
       "      <td>210.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-02-21</td>\n",
       "      <td>207.50</td>\n",
       "      <td>211.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5010</th>\n",
       "      <td>2002-01-17</td>\n",
       "      <td>1.92</td>\n",
       "      <td>1.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5011</th>\n",
       "      <td>2002-01-16</td>\n",
       "      <td>1.83</td>\n",
       "      <td>1.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5012</th>\n",
       "      <td>2002-01-15</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5013</th>\n",
       "      <td>2002-01-14</td>\n",
       "      <td>1.63</td>\n",
       "      <td>1.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5014</th>\n",
       "      <td>2002-01-11</td>\n",
       "      <td>1.65</td>\n",
       "      <td>1.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5015 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  buy_price  sell_price\n",
       "0    2022-02-25     207.00      211.00\n",
       "1    2022-02-24     206.50      210.50\n",
       "2    2022-02-23     206.00      210.00\n",
       "3    2022-02-22     206.00      210.00\n",
       "4    2022-02-21     207.50      211.50\n",
       "...         ...        ...         ...\n",
       "5010 2002-01-17       1.92        1.97\n",
       "5011 2002-01-16       1.83        1.87\n",
       "5012 2002-01-15       1.90        1.95\n",
       "5013 2002-01-14       1.63        1.68\n",
       "5014 2002-01-11       1.65        1.70\n",
       "\n",
       "[5015 rows x 3 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dollar_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec24d210-192d-458b-ada0-5456f561bcf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "849e5d4b-29ce-481c-81eb-92192eefd7bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date          datetime64[ns]\n",
       "buy_price            float64\n",
       "sell_price           float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dollar_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "81ec9c5b-18b9-4941-a190-a845392e3bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dollar_df['avg'] = (dollar_df['buy_price']+dollar_df['sell_price'])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cc761a27-0faa-44bb-b106-9045945bfb8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>buy_price</th>\n",
       "      <th>sell_price</th>\n",
       "      <th>avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-02-25</td>\n",
       "      <td>207.00</td>\n",
       "      <td>211.00</td>\n",
       "      <td>209.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-02-24</td>\n",
       "      <td>206.50</td>\n",
       "      <td>210.50</td>\n",
       "      <td>208.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-02-23</td>\n",
       "      <td>206.00</td>\n",
       "      <td>210.00</td>\n",
       "      <td>208.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-02-22</td>\n",
       "      <td>206.00</td>\n",
       "      <td>210.00</td>\n",
       "      <td>208.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-02-21</td>\n",
       "      <td>207.50</td>\n",
       "      <td>211.50</td>\n",
       "      <td>209.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5010</th>\n",
       "      <td>2002-01-17</td>\n",
       "      <td>1.92</td>\n",
       "      <td>1.97</td>\n",
       "      <td>1.945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5011</th>\n",
       "      <td>2002-01-16</td>\n",
       "      <td>1.83</td>\n",
       "      <td>1.87</td>\n",
       "      <td>1.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5012</th>\n",
       "      <td>2002-01-15</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1.925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5013</th>\n",
       "      <td>2002-01-14</td>\n",
       "      <td>1.63</td>\n",
       "      <td>1.68</td>\n",
       "      <td>1.655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5014</th>\n",
       "      <td>2002-01-11</td>\n",
       "      <td>1.65</td>\n",
       "      <td>1.70</td>\n",
       "      <td>1.675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5015 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  buy_price  sell_price      avg\n",
       "0    2022-02-25     207.00      211.00  209.000\n",
       "1    2022-02-24     206.50      210.50  208.500\n",
       "2    2022-02-23     206.00      210.00  208.000\n",
       "3    2022-02-22     206.00      210.00  208.000\n",
       "4    2022-02-21     207.50      211.50  209.500\n",
       "...         ...        ...         ...      ...\n",
       "5010 2002-01-17       1.92        1.97    1.945\n",
       "5011 2002-01-16       1.83        1.87    1.850\n",
       "5012 2002-01-15       1.90        1.95    1.925\n",
       "5013 2002-01-14       1.63        1.68    1.655\n",
       "5014 2002-01-11       1.65        1.70    1.675\n",
       "\n",
       "[5015 rows x 4 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dollar_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d4ee10-24df-4fb6-89ad-f73c9a7ec960",
   "metadata": {},
   "source": [
    "## Data exploration\n",
    "\n",
    "We will be using the Dash library to generate an environment where Plotly graphs will be rendered. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e24fe4ba-6fe3-47ca-8e82-d91c5054004e",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = JupyterDash(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ba692557-d928-423b-b1ad-e8a75ea3b6b7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = px.line(dollar_df, x='date', y='avg',labels=dict(date='Date', avg='ARSUSD informal rate'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e88ce282-19eb-410f-947b-3556f11a7361",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "app.layout = html.Div([\n",
    "    dcc.Graph(figure=fig),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "081d6c97-dc73-43fd-afff-330ba8d4603c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/synics-dev/.local/lib/python3.9/site-packages/jupyter_dash/jupyter_app.py:139: UserWarning:\n",
      "\n",
      "The 'environ['werkzeug.server.shutdown']' function is deprecated and will be removed in Werkzeug 2.1.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f4cc8d44e50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "app.run_server(mode=\"inline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e03c51-d59f-470a-bad4-5e18c98a4b2e",
   "metadata": {},
   "source": [
    "# Argentinian Newspaper front pages\n",
    "\n",
    "## Extraction\n",
    "\n",
    "I will be using a newspaper that offers a service to see the front page for every day. As we don't want to overuse a free service, I will keep a file that tracks the last downloaded picture, so that we everytime that this notebook is run, only the new pages will be downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85600f50-869b-4fc6-a23f-7b654ef31b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5391430f-9309-4848-ab77-b3b5ef41fdbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000-01-02 00:00:00\n",
      "https://tapas.clarin.com/tapa/2000/01/02/20000102_thumb.jpg\n",
      "https://tapas.clarin.com/tapa/2000/01/03/20000103_thumb.jpg\n",
      "https://tapas.clarin.com/tapa/2000/01/04/20000104_thumb.jpg\n",
      "https://tapas.clarin.com/tapa/2000/01/05/20000105_thumb.jpg\n",
      "https://tapas.clarin.com/tapa/2000/01/06/20000106_thumb.jpg\n",
      "https://tapas.clarin.com/tapa/2000/01/07/20000107_thumb.jpg\n",
      "https://tapas.clarin.com/tapa/2000/01/08/20000108_thumb.jpg\n",
      "https://tapas.clarin.com/tapa/2000/01/09/20000109_thumb.jpg\n",
      "https://tapas.clarin.com/tapa/2000/01/10/20000110_thumb.jpg\n",
      "https://tapas.clarin.com/tapa/2000/01/11/20000111_thumb.jpg\n"
     ]
    }
   ],
   "source": [
    "today = datetime.datetime.today()\n",
    "last_record = {\n",
    "    'last_record':'2000/01/02'\n",
    "}\n",
    "not_available_list = open('not_available_list','w+')\n",
    "# first we check if the file exists\n",
    "if os.path.exists('./records.json'):\n",
    "    open('records.json', 'r')\n",
    "else:\n",
    "    file = open('records.json', 'w+')\n",
    "    #in this situation, we have to donwload them all.\n",
    "    # let's start in 2000-01-01\n",
    "    date_cursor = datetime.datetime(2000,1,2)\n",
    "    date_add = datetime.timedelta(days=1)\n",
    "    \n",
    "    print(date_cursor)\n",
    "    a = 0\n",
    "    while date_cursor < datetime.datetime.today() and a < 10:\n",
    "        a+=1\n",
    "        date_string = date_cursor.strftime('%Y/%m/%d/%Y%m%d')\n",
    "        request_uri = f'https://tapas.clarin.com/tapa/{date_string}_thumb.jpg'\n",
    "        print(request_uri)\n",
    "        r = requests.get(request_uri)\n",
    "        if r.status_code == requests.codes.ok:\n",
    "            i = Image.open(BytesIO(r.content))\n",
    "            filename = date_cursor.strftime('%Y%m%d')\n",
    "            i.save(f'./{filename}.jpg')\n",
    "            last_record['last_record'] = filename\n",
    "        else:\n",
    "            print('Not available')\n",
    "        date_cursor = date_cursor + date_add\n",
    "    json_last_record = json.dumps(last_record)\n",
    "    file.write(json_last_record)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61036a3c-4ecd-4f72-bdfc-3341ef01b035",
   "metadata": {},
   "source": [
    "# Transformation\n",
    "\n",
    "There are many possible approaches here. The most naive of them all, the simplest, and, in my opinion, the one with the highest failure probability, is inputing the pictures directly into a Neural Network and trying to predict the behaviour of the informal dollar. \n",
    "\n",
    "I think this would be a bit tough for most models. So, my plan is to transform the pictures into text first. For this, I will be using RSLA to detect the text sections and extract them, and then, pytesseract to transform the images of text into actual text.  \n",
    "\n",
    "## Why am I not using archives of digital newspapers?\n",
    "\n",
    "Well, I am interested to see if just the data of a front page is enough to predict the price movements. Newspapers are not just text. They have specific layouts. Articles, titles, images, are given a certain size. Different colors are used. I will try to take all this into account when feeding the data into the NN. \n",
    "\n",
    "The transformation step will be quite large. Let's start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251b9d62-f3bb-4686-a1a5-fdb450df24c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
