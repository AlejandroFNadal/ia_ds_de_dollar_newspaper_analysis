{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88fe4c6b-c78b-4f00-a8ce-7f162e41ea64",
   "metadata": {},
   "source": [
    "# Title extraction\n",
    "\n",
    "The goal of this notebook is to extract images of the titles of each newspaper front page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d994268-3fa5-4ff9-ae83-dd80c61bdec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b4527c9-fac4-404f-9fd0-898f28613104",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_title(input_path:str, output_path:str):\n",
    "    img = cv2.imread(input_path)\n",
    "    \n",
    "    ## removing 20% top\n",
    "    height = img.shape[0]\n",
    "    header_size = int(height/5)\n",
    "    img = img[header_size:,:,:]\n",
    "    ## detecting lines\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # we use canny because it highlights the borders and edges, improving the results of HoughLinesP\n",
    "    edges = cv2.Canny(gray, 255, 255) \n",
    "    minLineLength = 150\n",
    "    maxLineGap = 3\n",
    "    lines = cv2.HoughLinesP(image=edges, rho=1, theta=np.pi/180.0, threshold=10, \n",
    "                        minLineLength = minLineLength, \n",
    "                        maxLineGap = maxLineGap)\n",
    "    if lines == []:\n",
    "        print(f'No lines found in {input_path} ')\n",
    "    else:\n",
    "        #remove lines by painting over them\n",
    "        for elem in lines:\n",
    "            for x1, y1, x2, y2 in elem:\n",
    "                cv2.line(img, (x1,y1), (x2, y2), (255, 255,255), 3)\n",
    "    ## remove main image looking for biggest areas\n",
    "    gray_no_lines = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    #black and white images work better for contour finding\n",
    "    ret, thresh = cv2.threshold(gray_no_lines, 230, 255, cv2.THRESH_BINARY)\n",
    "    # using the negative of the image gives better results\n",
    "    contours, hier = cv2.findContours(~thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE) \n",
    "    \n",
    "    areas = [[index, cv2.contourArea(c)] for index, c in enumerate(contours)]\n",
    "    #sorting the areas will allow us to eliminate the biggest ones choosing, in this case, two. The elimination is just painting a whole white rectangle on top of it\n",
    "    sorted_areas = sorted(areas, key = lambda x: x[1], reverse=True)\n",
    "    for i in range(0,2):\n",
    "        x,y,w,h = cv2.boundingRect(contours[sorted_areas[i][0]])\n",
    "        cv2.rectangle(img, (x,y), (x+w, y+h), (255,255,255),-1)\n",
    "    likely_img_pos = contours[sorted_areas[0][0]] #saving just in case we need it later\n",
    "    # get contours with biggest height\n",
    "    gray_no_lines = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    ret, thresh = cv2.threshold(gray_no_lines, 120, 255, cv2.THRESH_BINARY)\n",
    "    #ret, thresh = cv2.threshold(cv2.cvtColor(newspaper_borders, cv2.COLOR_BGR2GRAY), 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, hier = cv2.findContours(~thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE) #Important, external will give you only an external bounding box. Tree will give you every single\n",
    "    heights = [[index, cv2.boundingRect(c)[3]] for index, c in enumerate(contours) if cv2.boundingRect(c)[3]> 2]\n",
    "    heights_only = [elem[1] for elem in heights]\n",
    "    if heights_only == []:\n",
    "        print(input_path)\n",
    "        return -1\n",
    "    heights_only_np = np.array(heights_only)\n",
    "    q3 = np.quantile(heights_only_np, 0.93)\n",
    "    sorted_heights = sorted(heights, key = lambda x: x[1], reverse=True)\n",
    "    #calculate average height\n",
    "    avg_height = 0\n",
    "    for pair in sorted_heights:\n",
    "        avg_height +=pair[1]\n",
    "    avg_height = avg_height/len(sorted_heights)\n",
    "\n",
    "    #draw boxes for each letter\n",
    "    # save the boxes\n",
    "    letter_boxes = []\n",
    "    for i in range(0,len(sorted_heights)):\n",
    "        if sorted_heights[i][1] > q3:\n",
    "            x,y,w,h = cv2.boundingRect(contours[sorted_heights[i][0]])\n",
    "            letter_boxes.append([x,y,w,h])\n",
    "    ## eliminate boxes inside boxes\n",
    "    for coords in letter_boxes:\n",
    "        x, y, w, h = coords\n",
    "        i = 0\n",
    "        for other_coords in letter_boxes:\n",
    "            x2,y2,w2,h2 = other_coords\n",
    "            if x < x2 and y < y2 and x+w > x2+w2 and y+h > y2+h2:\n",
    "                letter_boxes[i] = [-1,-1,-1,-1]\n",
    "            i+=1\n",
    "    letter_boxes[:] = [elem for elem in letter_boxes if elem[0] != -1]\n",
    "    #drop boxes with small areas now out of letter_boxes\n",
    "    avg_area = 0\n",
    "    areas = []\n",
    "    for coords in letter_boxes:\n",
    "        area = coords[2]*coords[3]\n",
    "        avg_area += area\n",
    "        areas.append(area)\n",
    "    avg_area /= len(areas)\n",
    "    areas_array = np.array(areas)\n",
    "    std = np.std(areas_array)\n",
    "    letter_boxes[:] = [coords for coords in letter_boxes if coords[2]*coords[3] > avg_area]\n",
    "    \n",
    "    line_boxes = []\n",
    "    while letter_boxes != []:\n",
    "        comp_box = letter_boxes[0]\n",
    "        original_width = comp_box[2]\n",
    "        original_height = comp_box[3]\n",
    "        letter_boxes.pop(0)\n",
    "        #create the new line box\n",
    "        for coords in letter_boxes:\n",
    "            # if vertical position + height is similar, then most likely belongs to the same phrase\n",
    "\n",
    "            if abs(coords[1]+coords[3] - (comp_box[1]+comp_box[3])) < 10:\n",
    "\n",
    "                #if the x of the possible added box is less than the x of our comp_box, it is at our left\n",
    "                if coords[0] < comp_box[0]:\n",
    "\n",
    "                    #space analysis\n",
    "                    #if (coords[0]+coords[2] - comp_box[0]) < original_width + 20: # this might fail with spaces between words if the chosen letter is too small\n",
    "                    comp_box[2] = coords[2] + (-(coords[0] + coords[2]) + comp_box[0]) + comp_box[2] #w new box + gap + w old box\n",
    "                    comp_box[0] = coords[0] # correcting x\n",
    "                    comp_box[1] =  min(coords[1], comp_box[1])# for capital letters, some might be taller than others.\n",
    "                    comp_box[3] = max(coords[3],comp_box[3])\n",
    "                if coords[0] > (comp_box[0]+ comp_box[2]): # the new possible box is at the right:\n",
    "\n",
    "                    #print(comp_box, coords)\n",
    "                    #if (coords[0] - (comp_box[0] + comp_box[2])) < original_width + 20: # space check:\n",
    "                        #update comp_box\n",
    "                        # new w is orignial w + extra w + gap\n",
    "                    comp_box[2] += coords[2] + (coords[0] - (comp_box[0] + comp_box[2])) \n",
    "                    # x doesnt change\n",
    "                    comp_box[1] = min(coords[1], comp_box[1]) #pick the smallest y and the heighest h\n",
    "                    comp_box[3] = max(coords[3], comp_box[3])\n",
    "        # eliminate all boxes in the same height\n",
    "        letter_boxes[:] = [coords for coords in letter_boxes if abs((comp_box[1]+comp_box[3]) - (coords[1]+ coords[3])) > 10]\n",
    "\n",
    "        # add new line to line_list\n",
    "        line_boxes.append(comp_box)\n",
    "    #eliminate smaller boxes in width (these would not be titles but stuff that has survived to all the filtering before\n",
    "    # even if we eliminate some letter, it will still be obtained when we join all the lines\n",
    "    avg_width = 0\n",
    "    for coords in line_boxes:\n",
    "        avg_width += coords[2]\n",
    "    avg_width = avg_width / len(line_boxes)\n",
    "\n",
    "    line_boxes[:] = [coords for coords in line_boxes if coords[2] >= avg_width*0.7]\n",
    "    \n",
    "    #combine boxes\n",
    "    x, y, x2, y2 = line_boxes[0]\n",
    "    x2 += x# we need the actual coordinates for the second point of the rectangle\n",
    "    y2 += y \n",
    "    for coords in line_boxes:\n",
    "        if coords[0] < x:\n",
    "            x = coords[0]\n",
    "        if coords[1] < y:\n",
    "            y = coords[1]\n",
    "        if coords[0] + coords[2] > x2:\n",
    "            x2 = coords[0] + coords[2]\n",
    "        if coords[1] + coords[3] > y2:\n",
    "            y2 = coords[1] + coords[3]\n",
    "    #cv2.rectangle(img, (x,y), (x2,y2), (0,255,0), 3)\n",
    "    #we extract the image, adding a bit of extra margin on the bottom for good measure\n",
    "    title_img = img[y:(y2+20), x:x2]\n",
    "    cv2.imwrite(output_path, title_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1dccda8c-8c7b-4ecb-aa66-fbb94d98b634",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "43d4cead-918e-4df0-bec3-080915af4b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                             | 0/6485 [00:00<?, ?it/s]/tmp/ipykernel_5710/3157774762.py:17: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  if lines == []:\n",
      " 30%|███████████████████████████████████████▎                                                                                          | 1960/6485 [18:20<25:22,  2.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./InputImages/20090809.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6485/6485 [53:51<00:00,  2.01it/s]\n"
     ]
    }
   ],
   "source": [
    "log_file = open('logfile.txt','a')\n",
    "#we get the list of all elements in input images\n",
    "input_images = sorted(os.listdir('./InputImages'))\n",
    "#open continue from if exists\n",
    "try:\n",
    "    continue_from = open('continue_from', 'r')\n",
    "    file_to_start = continue_from.readline()\n",
    "    start_point = input_images.index(file_to_start)\n",
    "    input_images = input_images[start_point+1:]\n",
    "except:\n",
    "    pass\n",
    "isError=False\n",
    "for input_image in tqdm(input_images):\n",
    "    log_file.write(f'{input_image}\\n')\n",
    "    try:\n",
    "        extract_title(f\"./InputImages/{input_image}\", f\"./OutputImages/title_{input_image}\")\n",
    "    except:\n",
    "        isError=True\n",
    "        \n",
    "        continue_from = open('continue_from','w')\n",
    "        continue_from.write(input_image)\n",
    "        continue_from.close()\n",
    "if isError == False:\n",
    "    os.remove('./continue_from')\n",
    "log_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaffdb94-9407-4195-83fa-c83f380e117e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee8ba39-c3ed-4f5b-a58b-47f56b8a52e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
